\documentclass{article}           %% ceci est un commentaire (apres le caractere %)
\usepackage[utf8]{inputenc}   
%on me dit : usepackage avec l'option [latin1] mais ça foire... donc je prends utf8, du moment que c beau
\usepackage[T1]{fontenc}          %% permet d'utiliser les caractères accentués
\usepackage[french]{babel}
\usepackage[pdftex]{graphicx}
\usepackage{graphics}

\usepackage{graphics}
\usepackage{fancybox}		   %% package utiliser pour avoir un encadré 3D des images
\usepackage{fancyhdr}
\usepackage{makeidx}              %% permet de générer un index automatiquement
\usepackage[style=numeric,backend=bibtex]{biblatex}				%% Utilisé pour la biblio


\pagestyle{fancy}
\renewcommand\headrulewidth{1pt}
\fancyhead[L]{Proposition détaillée}
\fancyhead[R]{}
\fancyfoot[L]{}
\fancyfoot[R]{}



\title{Projet Scientifique Collectif X2013 \\INF02 : Synthétiseur automatique de documents}     %% \title est une macro, entre { } figure son premier argument
\author{Proposition détaillée}        %% idem
\date{24 septembre 2014}


\addbibresource{biblio.bib}
\begin{document}                  %% signale le début du document

\maketitle                        %% produire à cet endroit le titre de l'article à partir des informations fournies ci-dessus (title, author)


\newpage

\tableofcontents			
\newpage
%Remise par chaque groupe au coordinateur, au tuteur, au cadre référent et à la Scolarité Jaune, d’une proposition détaillée (10 à 15 pages hors annexes) :

\section*{Notre groupe}

\begin{itemize}
 \item Fernandes-Pinto-Fachada Sarah, \textbf{8\textsuperscript{e}} compagnie, section \textbf{équitation};
 \item Schrottenloher André, \textbf{8\textsuperscript{e}} compagnie, section \textbf{escrime};
 \item Angibault Antonin, \textbf{8\textsuperscript{e}} compagnie, section \textbf{escrime};
 \item Hufschmitt Théophane, \textbf{8\textsuperscript{e}} compagnie, section \textbf{escrime};
 \item Cao Zhixing, \textbf{9\textsuperscript{e}} compagnie, section \textbf{escalade};
 \item Boisseau Guillaume, \textbf{6\textsuperscript{e}} compagnie, section \textbf{natation};
\end{itemize}


\section{Présentation du sujet} %Enjeu et motivation du travail, objectif final

Nous cherchons à mettre sur pied un synthétiseur automatique de documents rédigés en langue anglaise, c'est à dire un programme capable de créer de résumer un ou plusieurs documents écrits dans cette langue.

\subsection{Motivation et enjeu}
Nous vivons dans un \^{a}ge d'abondance d'information, qu'il convient de traiter efficacement pour en profiter. Dans ce contexte, les synthétiseurs automatiques de textes ont bénéficié d'efforts croissants de recherche au cours des années passées. Notre travail s'inscrira dans cette démarche.


Un nombre non négligeable d'outils reposent, essentiellement, sur une extraction des phrases pertinentes \textit{via} une analyse statistique et éventuellement une analyse symbolique plus ou moins poussée (\textit{extractive summarization}). Nous voudrions, à l'instar de certains autres projets, mettre l'accent sur cette analyse de façon à donner une réelle compréhension des corpus à notre programme et, pour se convaincre de son succès, le pousser à la reformulation (\textit{abstractive summarization}).

Si nous y parvenons, nous espérons que ce programme sera moins enclin à négliger certaines idées importantes dans les textes sources sous prétexte qu'elles ne sont pas liées au reste du document par des liens sémantiques directs, mais au centre d'un réseau logique conséquent, que les outils extractifs.

\subsection{Objectif du projet}
Nous cherchons à résumer un texte ou un corpus de textes sur un sujet donné. \`{A} partir de ces textes, traitant d'un thème commun, le programme devra \textit{in fine} traduire les informations importantes en termes compréhensibles par un être humain.


Pour effectuer cette opération, nous envisageons l'approche suivante, telle que présentée dans \cite{jones_automatic_2007} :

\begin{enumerate}
 \item Effectuer une analyse syntaxique permettant de passer du texte écrit à un ensemble d'informations informatiquement exploitables (interprétation);
 \item Traiter ces informations, par exemple sous forme de réseau sémantique, afin d'en extraire les données pertinentes (transformation);
 \item Retraduire cette information pertinente en termes simples du point de vue du langage et de la syntaxe (génération).
\end{enumerate}


Nous ciblerons des textes d'actualité, dont la profusion fournira des données en quantité largement suffisante pour un traitement statistique éventuel, en plus de fournir un moyen simple d'évaluer notre programme (en comparant ses résumés à des résumés existants).

Dans la mesure où des outils pour la transcription d'un texte source en réseau sémantique exploitable par la machine (et vice-versa) existent, l'accent sera mis sur le traitement de l'information et la sélection de celles qui sont importantes ou sujettes à débat.

%Pour cela deux méthodes sont envisageables : la première reposera essentiellement sur une analyse statistique d'un grand nombre de textes pour déterminer où sont les unités de sens et comment elles s'accordent ; la seconde sur un réseau de concepts représentant le "bon sens" de notre programme. Dans la mesure où des outils d'extraction existent déjà, nous espérons aboutir à des résultats concrets en choisissant la méthode statistique ; c'est cependant la seconde méthode qui laisse le plus de place à l'innovation et que nous explorerons dans un premier temps, m\^{e}me si elle sera plus difficile à mettre en place.


\section{État de l'art} %Revue et analyse de l’état de l’art / des approches concurrentes ou alternatives
D'après~\cite{jones_automatic_2007}, des recherches sur la synthèse automatique de documents se sont principalement développées depuis les années 1990, motivées par des analyses statistiques remontant aussi loin que 1958. Les méthodes d'extraction, de par la simplicité de leur mise en œuvre, ont été le plus mises en avant, utilisant dans des travaux plus récents une analyse symbolique plus poussée, menant à la reformulation de la source plut\^{o}t que de la simple extraction de son contenu (on parle alors d'abstraction). Dans cette section, nous détaillerons les techniques propres à ces deux paradigmes, puis nous indiquerons les méthodes envisageables d'évaluation de la qualité des résumés produits.

\subsection{Extraction de la source (\emph{extractive summarization})}

% Nous prenons le problème sous l'angle de la compréhension du texte, mais en réalité, un plus grand nombre de travaux s'intéresse à l'extraction de phrases jugées pertinentes sur des critères statistiques.
L'idée de la méthode est d'extraire les phrases jugées importantes dans le texte et de les concaténer dans le résumé (en éliminant les redondances), après quelques modifications de forme de façon à assurer une plus grande cohérence de l'ensemble. Dans sa version la plus minimaliste, l'interprétation pourra se contenter de transcrire le texte à résumer (la source) en un tableau contenant le numéro de chaque phrase et une valeur (ou un vecteur, comme dans~\cite{fattah_ga_2009}) quantifiant son importance, la transformation devant alors simplement sélectionner les phrases les mieux notées. 

Ces méthodes ont donc souvent tendance à ignorer (ou faire peu de cas) du contenu sémantique de la source, se contentant de marquer la similarité entre phrases (parfois seulement du point de vue symbolique, donc en ignorant la synonymie), de la phrase au titre, etc.

L'établissement de la notation, au cours de l'interprétation, se fondera généralement sur une analyse statistique (fréquence d'apparition ou d'association de termes) et éventuellement sur une analyse plus fine des champs lexicaux et de la syntaxe.

\paragraph{}
Des méthodes d'extraction plus complexes existent, en faisant notamment intervenir des mesures de similarité entre unités syntaxiques (phrases, paragraphes) au sein d'un graphe de similarité. Dans~\cite{salton_automatic_1997}, les paragraphes les plus pertinents sont extraits du texte après établissement d'un tel graphe, sur la base de leur vocabulaire (précisément, des occurrences de \emph{termes}, qui peuvent être en première étude des mots~; il peut s'agir d'expressions indissociables à plusieurs mots telles que \textit{kick the bucket} en Anglais, qui signifie "mourir" et pas "donner un coup de pied dans le seau"). On repère alors par exemple ceux des paragraphes qui ont le plus de liens pertinents (au dessus d'une certaine similarité), en supposant qu'ils traitent simultanément d'un plus grand nombre de thèmes et sont donc plus représentatifs.

La méthode décrite dans~\cite{salton_automatic_1997} applique en fait à l'intérieur d'un texte des techniques de récupération  de l'information (\emph{information retrieval}) qui sont utilisées pour établir automatiquement des liens hypertextes entre pages web ou articles.
%Nous nous proposons de descendre au niveau des unités syntaxiques elles-mêmes, mais le traitement à effectuer se rapprochera très certainement de celui-ci et la mesure de pertinence des concepts sera sans doute proche de la mesure de pertinence des paragraphes.


\subsection{Méthodes non extractives}

Plusieurs raisons expliquent le développement relativement faible des méthodes non-extractives, comparé à celui des précédentes. Premièrement, les exigences sur la qualité des résumés produits étaient en général plutôt faibles~\cite{jones_automatic_2007}, et les méthodes extractives fournissent le plus souvent des résultats acceptables. La facilité relative de leur mise en œuvre leur a donc profité. D'autre part, les méthodes de résumé automatique se sont principalement développées incrémentalement à partir des premiers systèmes existants, ce qui n'a pas encouragé le développement de paradigmes concurrents et assez éloignés.

Bien que la limite entre les méthodes extractives et non-extractives soit un peu floue, on peut remarquer que ces dernières poussent l'analyse de la source nettement plus profondément lors de son interprétation. En effet, en sus de l'analyse symbolique, la représentation machine qui en est faite gardera un contenu sémantique (contrairement à certaines méthodes extractives) et contiendra plus d'informations que la représentation pour une méthode extractive (notamment, dans les systèmes les plus évolués, sur la structure générale de la source et de son argumentation éventuelle). Surtout, la génération sera une étape bien plus importante (au lieu de sélectionner du contenu depuis la source, le programme devra créer du contenu à partir de sa représentation transformée).

Ces méthodes sont, de manière générale, plus sensibles au contenu de la source que les méthodes extractives~\cite[p.1774]{jones_automatic_2007}, ce qui laisse envisager quelques difficultés à appliquer la méthode à des articles d'actualité (dont le contenu est essentiellement libre, donc varié). Nous la jugeons toutefois plus à même de tenir compte des points de désaccord entre plusieurs documents et donc plus capable de rendre compte des points de polémique dans les corpus étudiés. Pour pallier ce problème, nous réduirons donc le champ des articles étudiés à un domaine particulier (politique britannique ou sports par exemple).

Notons que les résultats escomptés pour des méthodes non extractives ne sont pas tout à fait les mêmes que pour les méthodes extractives ; en effet, les résumés obtenus ne sont pas linéaires, au sens où les idées peuvent ne pas suivre l'ordre du texte. Ils ne sont donc pas adaptés si l'on veut rendre compte de l'organisation de la source, en revanche ils le seront pour faire ressortir les idées majeures, par exemple en les insérant en début de résumé.

\subsection{Génération du résumé}
Une fois la représentation informatisée d'un texte effectuée, il faut retranscrire ces données en langage naturel afin d'obtenir un résumé.

Différentes recherches ont été menées~(\cite{danlos_generation_2000}, \cite{horacek_building_2001}) et il est possible de produire à partir de données un texte dans un domaine précis (météo, compte rendu médical, etc.). La restriction à un sujet permet de limiter le lexique en entrée et ainsi d'éviter différents problèmes d'homonymie, de synonymie ou de connotation. En effet, le choix, non seulement des mots, mais aussi de l'ordre de leur apparition et de la structure finale est l'un des problèmes majeurs de la génération de texte.

\subsection{Évaluation}

L'évaluation des programmes de résumé automatique n'est pas aussi évidente qu'elle le paraîtrait au premier abord. En effet leur évaluation en dehors de leur contexte d'utilisation est assez peu informative, et la grande variété sur la forme des sources (d'un texte de loi, très formel, à un scénario par exemple, en ne considérant que du texte) et la forme de la réponse attendue (par exemple entre une liste d'actions à mener lors d'un incendie, ou bien un bref article en prose) rend difficile la comparaison des systèmes entre eux. Trois méthodes principales ont été retenues par les programmes récents d'évaluation (à partir des années 2000)~\cite[p.1453-1461]{jones_automatic_2007}~:
\begin{description}
  \item [Qualité du texte et qualité du discours :] Pour des résumés sous forme de texte en langage naturel, il s'agit d'une part de vérifier la justesse grammaticale du résumé, ainsi que sa cohérence générale à plus grande échelle. Si les propriétés locales sont assez simplement vérifiables, c'est assez loin d'être le cas pour le discours en général.
  \item [Capture du concept :] Il s'agit de vérifier que les informations centrales de la source sont également présentes dans le résumé. Pour cela, une méthode assez prometteuse est de définir un certain nombre de questions sur la source auxquelles on devrait pouvoir répondre en ayant lu seulement le résumé. Il est concevable de définir ces questions à partir de questions de compréhension de texte basiques (du genre de celles qu'on donne en primaire) ou des questions un peu plus poussées sur la structure de l'argumentation. Cependant les questions auxquelles on doit pouvoir répondre restent essentiellement fonction de l'objectif du résumé et ne permettent donc pas d'évaluer le système en toute indépendance.
  \item [Comparaison à un modèle :] L'idée ici n'est pas de comparer le résumé à sa source mais à d'autres résumés établis comme bons. Ces modèles sont souvent créés par des humains (dont on suppose qu'ils sont entraînés à produire de bons résumés), même si cela limite la quantité des points de comparaison. Les difficultés de cette méthode résident, pour l'essentiel, à la comparaison d'un texte à l'autre (dès lors que les phrases ne sont plus simplement extraites de la source, il faut juger de l'équivalence ou de la proximité des concepts présents dans les résumés) et au désaccord des juges (ou rédacteurs) sur ce qui est important dans un texte.
 \end{description}
  
  Ce dernier point illustre une difficulté fondamentale de toute évaluation : la qualité essentielle du bon résumé est de contenir les informations clés présentes dans la source, une caractérisation vague et impossible à préciser. De plus, des résumés de forme très différente peuvent servir efficacement le même objectif. Cela a participé à l'efficacité modérés des synthétiseurs automatiques de textes : s'il est difficile de qualifier un bon résumé, on mesure le fait d'éviter des résumés pathologiquement mauvais.

\section{Traitement envisagé du sujet}

\subsection{Étapes-clés} %Objectifs intermédiaires, avec leur échéancier,

Comme présenté en début de ce document, le programme sera essentiellement décomposé en trois modules indépendants :
\begin{itemize}
 \item L'interprétation du texte source en données exploitables;
 \item La transformation des données;
 \item La génération du résumé.
\end{itemize}


\subsubsection{Interprétation du texte : analyse syntaxique et sémantique}

L'analyse syntaxique du texte sera effectuée par un outil déjà existant qui reste à déterminer. L'utilisation de la langue anglaise nous permet d'envisager d'utiliser des analyseurs syntaxiques \emph{open-source}, et notre tuteur, de l'entreprise française systran, nous a également proposé d'utiliser certains de ses outils.

Dans le pire des cas, il nous faudra enrichir un peu les données fournies par l'analyseur pour rendre compte, en partie au moins, de l'organisation logique du texte.

%Il s'agira donc d'abord d'effectuer des recherches bibliographiques sur les divers outils à notre disposition, puis dans un second temps d'apprendre à les ma\^{i}triser.



\subsubsection{Traitement des données}

Deux classes de méthodes sont envisageables pour traiter les données issues du premier module~:

\begin{itemize}
  \item La simple réduction de la taille des données : élaguer les branches les moins importantes ou les nœuds les plus faibles en terme de poids ou de relations~; éventuellement appliquer un algorithme de regroupement (\emph{clustering}) sur les nœuds dans le cas où les données sont représentées par un graphe, etc.
  
  \item Faire intervenir des données supplémentaires sous la forme d'un réseau sémantique, représentant en première approximation le bon sens du programme et qui influencera la lecture du texte et l'importance relative des idées perçues. Ce réseau sera appelé \textit{réseau bon sens} dans la suite.
\end{itemize}
La seconde possibilité sera explorée d'abord, puis s'il s'avère impossible de produire une avancée quelconque dans le temps imparti, nous nous rabattrons sur la première.

\subsubsection{Génération du résumé}

Une fois la transformation faite, nous utiliserons à nouveau un outil déjà existant pour générer le résumé final. Nous nous efforcerons de choisir un programme acceptant des données conformes à la représentation qui sera faite de la source (qui sera très semblable à celle de la source transformée). Cela sera donc déterminant dans le choix de l'outil.

\subsection{Plan de travail}

Nous prévoyons d'articuler notre projet en 3 étapes :

\begin{description}
	\item[Octobre-Novembre :]Choix des outils, définition précise des objectifs et moyens.
	\item[Décembre-Janvier :]Implémentation du réseau bon sens et de ses interactions avec les données.
	\item[Janvier-Avril :]Finalisation du code, apprentissage par le programme et tests.
\end{description}

\subsubsection{1\textsuperscript{ère} étape}

Comme précisé plus haut, nous utiliserons des outils existants pour les phases d'interprétation et de génération de notre programme. Le format d'entrée de l'outil de génération devra \^{e}tre adapté au format de sortie de notre module de transformation, ce qui sera plus déterminant dans le choix de l'outil que la qualité de la sortie : le cœur de notre projet est en effet la sélection des concepts importants et pas la mise en forme de ces concepts.

\paragraph{}
Au centre de cette sélection, justement, se situera le réseau bon sens dont il faudra définir précisément :
\begin{description}
	\item[Les capacités exactes :]Nous prévoyons de l'utiliser comme grille de lecture sur les représentations de la source, par analogie avec la connaissance \textit{a priori} sur le sujet d'un humain souhaitant résumer un texte. Il devra donc, d'une manière ou d'une autre, \^{e}tre capable de reconna\^{i}tre certaines unités comme des évènements insécables (printemps arabe, Boston bombing par exemple) et les utiliser pour agir sur la source, renforçant certains liens sémantiques pour en affaiblir d'autres.
	\item[L'implémentation physique :]Il s'agira probablement au moins d'un graphe dont les noeuds représenteraient des idées, et les arcs des liens logiques.
\end{description}

C'est aussi au cours de cette période que nous fixerons le domaine d'étude. Pour cela, nous prévoyons de lire une série d'articles et sélectionner un domaine qui semble à la fois abordable et intéressant.

\subsubsection{2\textsuperscript{e} étape}

Le succès de cette étape dépendra grandement des définitions établies auparavant. D'ici la fin janvier, notre objectif est d'\^{e}tre en bonne voie sur la réalisation concrète du code, c'est à cette période que nous serons en mesure de sentir concrètement si les objectifs étaient trop ambitieux et s'il faut se ramener à un système plus simple. Dans le cas contraire, nous serions en mesure de commencer à faire interagir le réseau bon sens avec des données sources.

Il s'agira bien, dans le meilleur des cas, d'interaction : nous espérons, sans l'établir en priorité absolue, permettre à notre réseau d'évoluer en fonction des résumés qu'il produit (encore une fois par analogie avec le cas humain : un nouveau texte résumé procure de nouvelles connaissances sur le sujet).

\subsubsection{3\textsuperscript{e} étape}

Au cours de cette étape, le choix final du système sera effectué et il ne restera plus qu'à finaliser son implémentation, poursuivre (le cas échéant) son apprentissage et commencer à quantifier ses performances.


\subsection{Répartition des tâches}%Méthodes, organisation du travail,  répartition des tâches
\begin{itemize}
	\item Chef de projet, contact avec l'encadrement : Antonin Angibault
	\item Contact avec le tuteur : Théophane Hufschmitt
	\item Établissement de la bibliographie : Antonin Angibault, André Schrottenloher
	\item Obtention d'outils : Guillaume Boisseau
\end{itemize}

%Identification des moyens auxquels le projet fera appel : moyens mobilisables à l’Ecole (TREX, laboratoires, ateliers, binets…), achats à prévoir…
%Contributions de partenaires  internes (laboratoires, binets) et externes (entreprises, organismes)
%Eventuels résultats préliminaires
%Références bibliographiques (publications, brevets…)
%Annexes : devis des achats à prévoir, demande de financement
\section{Glossaire}

\begin{description}
	\item[Réseau sémantique :]Graphe orienté dont les sommets sont étiquetés par des mots ou unités de sens, et dont les arcs représentent des liens d'appartenance, de conséquence, de proximité conceptuelle, entre les sommets. Ces arcs peuvent aussi \^{e}tre étiquetés pour rendre compte d'une proximité plus ou moins importante. Ils peuvent \^{e}tre utilisés pour la représentation de la connaissance, ce qui rend leur utilisation pertinente ici.
	\item[Analyse symbolique :]Étude de la langue du point de vue des signes. Dans une analyse symbolique, les mots "simultanés" et "concomitants" seront perçus comme à peu près sans rapport.
	\item[Analyse sémantique :]Étude de la langue du point de vue du sens. Dans l'exemple précédent les mots seront vus comme très proches puisqu'ils sont synonymes.
\end{description}

\section{Références bibliographiques}

\nocite{*}
\printbibliography



\appendix
%\section{Les annexes}



\end{document}
