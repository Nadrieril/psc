\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}%%seul package à charger~: pour éviter les problèmes sordides d'encodage
\usepackage[rapport,psc]{andre}%%bon eh bien sûr...

\usepackage{makeidx}              %% permet de générer un index automatiquement
\usepackage[style=numeric,backend=bibtex]{biblatex}				%% Utilisé pour la biblio



\title{Projet Scientifique Collectif X2013 \\INF02~: Synthétiseur automatique de documents} 
\renewcommand{\petittitre}{Projet INF02}
\author{\membres} %%\membres uniquement avec l'option psc
\date{21 janvier 2015}

%mettre les accents comme \c{c}a, sinon risque de plantage
\index{R\'eseau S\'emantique}
\index{Analyse Symbolique}
\index{Analyse S\'emantique}
\index{R\'eseau de Concepts}

\makeindex
\addbibresource{biblio.bib}
\begin{document}

\titrelong{}


\tableofcontents			
\newpage

\section{Rappel du projet}

\subsection{Notre groupe}
\begin{itemize}
 \item Fernandes-Pinto-Fachada Sarah, \textbf{8\textsuperscript{e}} compagnie, section \textbf{\'equitation};
 \item Schrottenloher Andr\'e, \textbf{8\textsuperscript{e}} compagnie, section \textbf{escrime};
 \item Angibault Antonin, \textbf{8\textsuperscript{e}} compagnie, section \textbf{escrime};
 \item Hufschmitt Th\'eophane, \textbf{8\textsuperscript{e}} compagnie, section \textbf{escrime};
 \item Cao Zhixing, \textbf{9\textsuperscript{e}} compagnie, section \textbf{escalade};
 \item Boisseau Guillaume, \textbf{6\textsuperscript{e}} compagnie, section \textbf{natation};
\end{itemize}

\subsection{Notre sujet}

\subsubsection{But du projet}

Le but de notre sujet est de produire un programme capable d'analyser s\'emantiquement\index{Analyse S\'emantique} un texte ayant pour sujet le sport (et plus particulièrement encore le football) de façon à en produire un résumé. Il s'agit là d'une véritable innovation par rapport à l'état actuel du résumé automatique, dans la mesure où les programmes existants se basent prioritairement sur une analyse statistique plus ou moins poussée de fréquence d'apparition des mots pour juger de leur importance~; notre programme se baserait plutôt sur le sens pour juger de la pertinence d'un concept et savoir s'il doit le faire figurer ou non dans le résumé final.

Dans l'état actuel des choses, nous n'espérons pas produire un programme utilisable dans l'industrie ou plus efficace que ceux déjà existants~; nous pensons en revanche que cette autre manière d'aborder le résumé automatique est plus viable, dans la mesure où elle analyse plus directement que par la méthode statistique.

\subsubsection{Modules du projet et répartition du travail}
Pour atteindre cet objectif, plusieurs modules assez indépendants ont pu être identifiés et traités séparément~:

\begin{description}
	\item[R\'ecup\'eration de donn\'ees] à utiliser pour la création d'un réseau de concepts modélisant la connaissance \textit{a priori} du programme. Responsables : Théophane Hufschmitt, Guillaume Boisseau.
	\item[Création du réseau de concepts] et remplissage de celui-ci. Il s'agissait ici d'une part de définir sa structure et d'autre part d'y introduire les données nécessaires. Responsables : André Schrottenloher, Guillaume Boisseau.
	\item[Analyse syntaxique] à l'aide d'outil existants. Il s'agissait de trouver une grammaire capable d'analyser une phrase et d'en faire ressortir les relations de type verbe-objet ou nom-qualificatif. Responsables : Antonin Angibault, Théophane Hufschmitt, Sarah Fernandes-Pinto-Fachada
	\item[Réflexion] sur l'utilisation du réseau de concepts et de l'analyse grammaticale pour produire un réseau capable de rendre compte de la compréhension du texte. Responsables : tous.
	\item[Implémentation] d'un algorithme simple de résumé stastique (basé sur l'algorithme TF-IDF), devant servir de base de comparaison pour tester la qualité des résumés produits par notre algorithme.  Responsable : Zhixing Cao. 
\end{description}

\subsubsection{Outils extérieurs utilisés}

Le volume de travail représenté par la création et l'utilisation du réseau de concepts\index{r\'eseau de concepts} est tel que nous nous appuyons sur un certain nombre d'outils pour traiter le texte en amont de notre résumé. La construction du réseau s'appuie, elle aussi, sur des bases de connaissances déjà existantes (et libres) dont voici la liste :

\begin{itemize}
	\item[Wordnet~: ]Dictionnaire permettant d'obtenir la classe grammaticale des mots présents dans le réseau.
	\item[Conceptnet~: ]Grande base de connaissances permettant d'établir la proximité conceptuelle entre différents termes du réseau.
	\item[Freebase~: ]Cette base de connaissance permet d'identifier les noms propres, tels que les joueurs de foot ou les différents stades.
	\item[Natural Language ToolKit (nltk)~: ]Divers outils grammaticaux pour l'étude du langage naturel.
\end{itemize}

\section{\'Etat d'avancement~: r\'ecup\'eration de donn\'ees}

\section{Le r\'eseau de concepts}


\subsection{Structure}


\begin{definition}[Réseau de concepts]
Le réseau de concepts\index{R\'eseau de Concepts} est la ``mémoire à long terme'' de notre programme.

Ce réseau est au carrefour entre les réseaux sémantiques et les réseaux de neurones. Les n\oe{}uds du réseau ne représentent pas des concepts à proprement parler~; en revanche, les concepts sont vus comme regroupant des n\oe{}uds fortement interconnectés.
\end{definition}


Le RC est constitué de n\oe{}uds. Chaque n\oe{}ud comporte~:
\begin{itemize}
  \item Une étiquette (mot)~;
 \item Une importance conceptuelle (IC) ou profondeur conceptuelle~;
 \item Une activation (A) initialement nulle~;
 \item Un certain nombre de liens à d'autres n\oe{}uds.
\end{itemize}

Chaque lien comporte~:
\begin{itemize}
 \item Une proximité conceptuelle (P)~;
 \item Une étiquette que nous reprenons sur le modèle de conceptnet
\end{itemize}

\subsection{Construction}

\subsubsection{Provenance des données~?}

Le but est donc de créer un réseau de concepts de base, que nous puissions utiliser comme base de connaissances dans le domaine considéré (ici le sport, mais nous pourrions avoir sélectionné un autre domaine).

Nous utilisons deux types de sources~:
\begin{itemize}
 \item Des articles de sport (données brutes) qui contiennent entre autres ``ce qu'il faut savoir''~;
 \item Des données sémantiques libres.
\end{itemize}

\subsubsection{Construction du réseau, première étape}

Après la lecture d'un grand nombre d'articles provenant de sources diverses (flux rss et sites d'information consacrés au sport), ceux-ci sont analysés pour en retirer un certain nombre de concepts sous forme normale. Cette opération se traduit dans la pratique en~:
\begin{itemize}
 \item Découpage du texte en phrases et en mots (tokens)~;
 \item Utilisation du part-of-speech tagger par défaut de nltk~;
 \item Récupération des noms propres et mise à part de ceux-ci~;
 \item Suppression des conjonctions de coordination, pronoms et autres mots qui ne sont pas de véritables concepts~;
 \item Il reste alors des adjectifs, adverbes, noms et verbes. Nous utilisons morphy de wordnet, ainsi qu'un morceau de code déjà utilisé pour construire conceptnet5 à partir de wordnet (voir partie suivante), pour transformer chaque terme en sa forme normale. Les noms sont mis au singulier, les verbes à l'infinitif\ldots
 \item Les termes restants sont alors tous les concepts auxquels le texte fait appel. Nous savons désormais que ces concepts devront apparaître dans le réseau, sauf exception (erreur à l'une des étapes)~;
 \item De manière générale, un concept qui apparaît au moins deux fois dans l'ensemble du corpus considéré peut être considéré comme valide (il y a toujours un risque d'erreur, mais il a été minimisé).
\end{itemize}


\subsubsection{WordNet}

WordNet est un dictionnaire complet contenant une grande quantité d'informations sur les mots.

Nous l'utilisons à travers son interface nltk, pour récupérer des informations sur les mots et les mettre sous forme normale.


\subsubsection{Conceptnet5}

ConceptNet est un projet libre de réseau sémantique représentant des connaissances usuelles, aussi bien de la vie de tous les jours, culturelles, scientifiques. Il fait partie du Commonsense Computing Initiative qui relie différents laboratoires, dont le MIT Media Lab, et entreprises.

Il est important de noter que conceptnet5 est généré à partir de données brutes. Conceptnet5 est relié à DBPedia, une grande partie de ses connaissances provient de Wiktionary, une partie de WordNet.
``The knowledge in ConceptNet is collected from a variety of resources, including crowd-sourced resources (such as Wiktionary and Open Mind Common Sense), games with a purpose (such as Verbosity and nadya.jp), and expert-created resources (such as WordNet and JMDict).''

Page web du projet~:
http://conceptnet5.media.mit.edu/

Le code python permettant de générer conceptnet5 à partir de données brutes est sur la page~:
https://github.com/commonsense/conceptnet5

\subsubsection{Structure de conceptnet5}

Conceptnet5 est un graphe sémantique de 
les n\oe{}uds sont des mots et de courtes phrases, dans un certain nombre de langages possibles. Les arêtes qui relient ces n\oe{}uds expriment une connaissance, elles expriment chacune une relation particulière.

Une arête possède aussi une source (d'où provient l'information) et un poids en fonction de cette source, selon l'importance de l'arête.

Une relation concept-arête-concept exprime une assertion. Une même assertion peut être exprimée de différentes manières.

Une assertion peut elle-même être utilisée comme un n\oe{}ud ou comme une arête (on peut avoir des assertions d'assertions).

Les relations valables dans tout langage, pour ConceptNet5, sont par exemple~: 
\begin{itemize}
 \item RelatedTo
 \item IsA
 \item PartOf
 \item MemberOf
 \item HasA
 \item UsedFor
 \item CapableOf
 \item AtLocation
 \item Causes
 \item HasSubevent
 \item HasFirstSubevent
 \item HasLastSubevent
 \item HasPrerequisite
 \item HasProperty
 \item MotivatedByGoal
 \item ObstructedBy
 \item Desires
 \item CreatedBy
 \item Synonym
 \item Antonym
 \item DerivedFrom
 \item TranslationOf
 \item DefinedAs
\end{itemize}

https://github.com/commonsense/conceptnet5/wiki/Relations

La correspondance entre relations de WordNet et de Conceptnet est par exemple~:
\begin{itemize}
 \item `attribute': `Attribute',
 \item `causes': `Causes',
 \item `classifiedByRegion': `HasContext',
 \item `classifiedByUsage': `HasContext',
 \item `classifiedByTopic': `HasContext',
 \item `entails': `Entails',
 \item `hyponymOf': `IsA',
 \item `instanceOf': `InstanceOf',
 \item `memberMeronymOf': `MemberOf',
 \item `partMeronymOf': `PartOf',
 \item `sameVerbGroupAs': `SimilarTo',
 \item `similarTo': `SimilarTo',
 \item `substanceMeronymOf': `MadeOf',
 \item `antonymOf': `Antonym',
 \item `derivationallyRelated': `DerivedFrom',
 \item `pertainsTo': `PertainsTo',
 \item `seeAlso': `RelatedTo',
\end{itemize}

Nous avons décidé après coup de conserver ces relations dans le réseau de concepts, et d'en utiliser un sous-ensemble.

\subsubsection{Détail de l'API}

Nous pouvons faire un certain nombre de requêtes à Conceptnet5. Il existe trois types différents de requêtes~:
\begin{itemize}
 \item Lookup
 \item Association
 \item Search
\end{itemize}
Association permet de calculer la proximité entre deux concepts, ou de récupérer une liste de concepts proches d'un concept donné.

Search permet de récupérer une liste d'arêtes (edges) entre concepts, selon les paramètres spécifiés (le plus souvent, on impose le concept de départ start ou d'arrivée end). 

Lookup permet d'analyser un concept (on aura par exemple accès à des listes d'arêtes dans lequel il intervient).


\subsubsection{Utilisation de Conceptnet5}

Nous utilisons en majorité Association et Search.
Étant donné un concept dont nous savons qu'il doit être étendu, nous utilisons conceptnet5 pour créer de nouveaux concepts au sein du réseau, et pour ajoutr de nouveaux liens. Une première requête de type Search permet d'avoir accès à un certain nombre de liens vers d'autres concepts, qui sont ajoutés (on ne récupère que les plus pertinents). Une requête de type Association permet de créer de nouveaux liens vers d'autres concepts similaires.

Nous ajoutons alors une arête SimilarTo.



    
\subsubsection{Freebase}

Freebase est une immense base de données sémantiques qui contient beaucoup d'informations sur des noms propres notamment. Le projet, repris par google mais sous une license qui laisse les données libres d'accès, de téléchargement et d'utilisation, a lui aussi une API, un peu plus complexe que celle de conceptnet5. Freebase permet notamment de récuperer des informations sur une personne à partir de son nom, et à peu de frais, de vérifier que cette personne existe bel et bien.

    
    

\section{Traitement du r\'eseau}

Le réseau de concepts représente, comme nous l'avons déjà dit, la connaissance \textit{a priori} de notre programme sur le domaine étudié. Pour étudier un texte particulier, il s'agit maintenant de faire agir ce texte sur nos connaissances et d'interpréter l'effet que cette lecture a.

Deux méthodes ont été envisagées : la première étudiait, essentiellement, la différence entre l'état du réseau de concepts avant et après la lecture et devait en déduire les faits importants. La seconde, qui a finalement été retenue, s'appuie sur une activation des concepts dans le réseau, puis une instanciation des concepts fortement activés dans un espace de travail appelé \textit{workspace}\index{workspace}. Ces concepts instanciés sont par la suite capable d'effectuer des tâches plus complexes relatives à la compréhension du texte.

Quelle que soit la méthode employée, une analyse syntaxique\index{analyse syntaxique} préalable du texte est nécessaire pour rendre compte de sa compréhension et utiliser au mieux notre réseau de connaissance.

\subsection{Workspace}\index{workspace}


\subsection{Analyse syntaxique}\index{analyse syntaxique}

Cette partie ne constituant pas le c\oe{}r de notre psc, nous avons décidé d'utiliser un outil déjà codé, faisant partie de la plus grande librairie libre nltk\index{Natural Language ToolKit}.

\subsubsection{Description algorithmique d'une grammaire}\index{grammaire}
Une grammairep peut être décrite informatiquement de manière très simple. En effet, on peut la voir comme~:
\begin{itemize}
	\item Un ensemble de classes terminales (verbe, nom par exemple) associées à une liste de mots ou éventuellement d'expressions
	\item Un ensemble de règles, souvent sous la forme d'une reconnaissance de motifs, permettant de découper une phrase en plusieurs éléments (et finalement en unités syntaxiques élémentaires).
\end{itemize}

Il y a par conséquent deux manières pour une grammaire d'être incomplète~: soit elle ne connaît pas assez de vocabulaire (manque d'éléments dans les cas terminaux), soit elle ne connaît pas assez de règles. La première faille est assez facile à combler par des requêtes vers WordNet\index{Wordnet} (et par ailleurs un outil automatique est inclus dans nltk\index{Natural Language ToolKit}~; il est en revanche assez indispensable d'avoir une grammaire complète en termes de règles car il est beaucoup plus difficile d'inventer des manières de découper une phrase.

\subsubsection{\'Etat du texte en fin d'analyse}
Les grammaires nltk sont classées selon la forme de leur sortie. Elles attendent la liste des mots dans l'ordre dans lequel ils apparaissent dans le texte à étudier, accompagnés d'une liste de classes possibles pour ces mots. En sortie, on peut trouver~:

\begin{itemize}
	\item Un arbre représentant une structure grammaticale possible pour la phrase.
	\item La liste de tous les arbres pouvant représenter la structure grammaticale de la phrase.
	\item La liste de tous les arbres pouvant représenter la structure grammaticale de la phrase, et pour chaque arbre une mesure de la vraisemblance de cette structure.
\end{itemize} 

Il y a une grande différence entre les n\oe{}uds non terminaux des arbres en sortie et leurs feuilles. En effet, ces dernières seront les unités syntaxiques présentes à l'origine dans la phrase, tandis que les n\oe{}uds internes représentent la classe grammaticale des bouts de phrases représentés par les sous-arbres dont ils sont la racine.

%Un exemple serait sûrement le bienvenu, je vais voir si je me chauffe pour faire un ParseTree a l'air plausible. (Antonin)
%Cela étant n'hésitez pas à vous chauffer vous aussi.

Les n\oe{}uds internes sont en nombre fini et leurs étiquettes dépend de si on considère des grammaires sans contexte (capables de séparer des composants autour d'un verbe) ou des grammaires à dépendance (dont le but est d'identifier le sujet et les compléments du verbe central).


\section{Suites envisag\'ees}

\section{R\'ef\'erences bibliographiques}

\nocite{*}
\printbibliography{}



\appendix

\printindex


\end{document}



